{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c268199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in e:\\anaconda\\lib\\site-packages (4.5.4.60)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy>=1.17.3 in e:\\anaconda\\lib\\site-packages (from opencv-contrib-python) (1.20.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15dd9a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in e:\\anaconda\\lib\\site-packages (4.5.4.60)\n",
      "Requirement already satisfied: numpy>=1.17.3 in e:\\anaconda\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "% pip install opencv-python --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6db19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(np_image):\n",
    "    \"\"\"\n",
    "    This is a display function that we have added to show numpy images at full size\n",
    "    If you pass in an image with 3 channels, it will be displayed in RGB\n",
    "    If you passn in an image with 1 channel, it will be displayed in grayscale\n",
    "    \"\"\"\n",
    "    dpi = matplotlib.rcParams['figure.dpi']\n",
    "    if len(np_image.shape) == 3:\n",
    "        height, width, depth = np_image.shape\n",
    "    else:\n",
    "        height, width = np_image.shape\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image in either RGB or grayscale (depending on the amount of dimensions)\n",
    "    if (len(np_image.shape) >= 3):\n",
    "        ax.imshow(np_image)\n",
    "    else:\n",
    "        ax.imshow(np_image, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27dbad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Test on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn_DetectionModel('yolov4-tiny-custom29.cfg', 'yolov4-tiny-custom29_final.weights')\n",
    "net.setInputSize(416, 416)\n",
    "net.setInputScale(1.0 / 255)\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "frame = cv2.imread('./test-pig.jpg')\n",
    "\n",
    "with open('obj.names', 'rt') as f:\n",
    "    names = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "classes, confidences, boxes = net.detect(frame, confThreshold=0.1, nmsThreshold=0.4)\n",
    "\n",
    "for classId, confidence, box in zip(classes.flatten(), confidences.flatten(), boxes):\n",
    "    left, top, width, height = box\n",
    "    plt.imshow(frame[top:top + height, left:left + width])\n",
    "\n",
    "for classId, confidence, box in zip(classes.flatten(), confidences.flatten(), boxes):\n",
    "    label = '%.2f' % confidence\n",
    "    label = '%s: %s' % (names[classId], label)\n",
    "    labelsize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    left, top, width, height = box\n",
    "    top = max(top, labelsize[1])\n",
    "    cv2.rectangle(frame, box, color=(2, 255, 0), thickness=2)\n",
    "    cv2.rectangle(frame, (left, top - labelsize[1]), (left + labelsize[0], top + baseLine), (255, 255, 255), cv2.FILLED)\n",
    "    cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "cv2.imshow('out', frame)\n",
    "\n",
    "# destroy window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830b6d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Test on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "net = cv2.dnn_DetectionModel('yolov4-tiny-custom29.cfg', 'Copy_of_yolov4-tiny-custom29_best.weights')\n",
    "net.setInputSize(416, 416)\n",
    "net.setInputScale(1.0 / 255)\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "tail_ear = cv2.dnn_DetectionModel('taiL_ear.cfg', 'taiL_ear.weights')\n",
    "tail_ear.setInputSize(416, 416)\n",
    "tail_ear.setInputScale(1.0 / 255)\n",
    "tail_ear.setInputSwapRB(True)\n",
    "\n",
    "tail_classifier = keras.models.load_model('tail-classifier.hdf5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def predict_tail(model_, img):\n",
    "    pred_classes = ['curly', 'straight']\n",
    "    input_im = cv2.resize(img, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1, 224, 224, 3)\n",
    "    predictions = model_.predict(input_im)\n",
    "\n",
    "    closest_guess = None\n",
    "    index_guess = 0\n",
    "    prob_guess = 0\n",
    "\n",
    "    for pre in predictions[0]:\n",
    "        if pre > prob_guess:\n",
    "            prob_guess = pre\n",
    "            closest_guess = index_guess\n",
    "        index_guess = index_guess + 1\n",
    "\n",
    "    return pred_classes[closest_guess]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1286c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = 'Cam2-3.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_before.avi', fourcc, 20.0, size)\n",
    "\n",
    "frame_number = 0\n",
    "\n",
    "with open('obj.names', 'rt') as f:\n",
    "    names = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame_number += 1\n",
    "    counter = 0\n",
    "    tail_dict = {}\n",
    "\n",
    "    if ret:\n",
    "        classes, confidences, boxes = net.detect(frame, confThreshold=0.45, nmsThreshold=0.45)\n",
    "        pig_index = 0\n",
    "        display_index = 0\n",
    "        for classId, confidence, box in zip(classes.flatten(), confidences.flatten(), boxes):\n",
    "            counter = counter + 1\n",
    "            left, top, width, height = box\n",
    "            image = frame[top:top + height, left:left + width]\n",
    "            classes_te, confidences_te, boxes_te = tail_ear.detect(image, confThreshold=0.4, nmsThreshold=0.4)\n",
    "\n",
    "            for classId_tail_ear, box_tail in zip(classes_te, boxes_te):\n",
    "                if classId_tail_ear == 0:  #tail\n",
    "                    left, top, width, height = box_tail\n",
    "                    tail = predict_tail(tail_classifier, image[top:top + height, left:left + width])\n",
    "                    tail_dict[pig_index] = tail\n",
    "\n",
    "            pig_index = pig_index + 1\n",
    "\n",
    "        for classId, confidence, box in zip(classes.flatten(), confidences.flatten(), boxes):\n",
    "            label = '%.2f' % confidence\n",
    "            if display_index in tail_dict.keys():\n",
    "                label = '%s(%s tail): %s' % (names[classId], tail_dict[display_index], label)\n",
    "            else:\n",
    "                label = '%s(tail not visible): %s' % (names[classId], label)\n",
    "            labelsize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            left, top, width, height = box\n",
    "            top = max(top, labelsize[1])\n",
    "            cv2.rectangle(frame, box, color=(2, 255, 0), thickness=2)\n",
    "            cv2.rectangle(frame, (left, top - labelsize[1]), (left + labelsize[0], top + baseLine), (255, 255, 255),\n",
    "                          cv2.FILLED)\n",
    "            cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "            display_index = display_index + 1\n",
    "\n",
    "        out.write(frame)\n",
    "        # cv2.namedWindow('Objet Detection YOLO',cv2.WINDOW_NORMAL)\n",
    "        # cv2.resizeWindow('Objet Detection YOLO', 1600,900)\n",
    "        # cv2.imshow(\"Objet Detection YOLO\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 13:  #13 is the Enter Key\n",
    "            break\n",
    "    else:\n",
    "        print(frame_number)\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "combine 2 classifiers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<dnn_Model 00000225528EF210>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = cv2.dnn_DetectionModel('yolov4-tiny-custom29.cfg', 'Pig_detection_model.weights')\n",
    "net.setInputSize(416, 416)\n",
    "net.setInputScale(1.0 / 255)\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "tail_ear = cv2.dnn_DetectionModel('tail+ear.cfg', 'tails+ear.weights')\n",
    "tail_ear.setInputSize(416, 416)\n",
    "tail_ear.setInputScale(1.0 / 255)\n",
    "tail_ear.setInputSwapRB(True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logging function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#importing the module\n",
    "import json\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execute the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class PigData:\n",
    "    def __init__(self, pig_pos, pig_size, tail_type, tail_pos, tail_size, ear_pos, ear_size, ear_visible):\n",
    "        self.pig_pos = pig_pos\n",
    "        self.pig_size = pig_size\n",
    "        self.tail_type = tail_type\n",
    "        self.tail_size = tail_size\n",
    "        self.tail_pos = tail_pos\n",
    "        self.ear_pos = ear_pos\n",
    "        self.ear_size = ear_size\n",
    "        self.ear_visible = ear_visible\n",
    "\n",
    "    def toJson(self):\n",
    "        return json.dumps({'pig_pos': self.pig_pos, 'pig_size': self.pig_size,\n",
    "                           'tail_type':self.tail_type, 'tail_size':self.tail_size,\n",
    "                           'tail_pos':self.tail_pos, 'ear_pos': self.ear_pos, 'ear_size': self.ear_size, 'ear_visible': self.ear_visible\n",
    "        }, sort_keys=True, indent=4)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.toJson()\n",
    "\n",
    "class Frame:\n",
    "    def __init__(self, f_number, total_pig, pigs_data):\n",
    "        self.f_number = f_number\n",
    "        self.total_pig = total_pig\n",
    "        self.pigs_data = pigs_data\n",
    "\n",
    "    def toJson(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.toJson()\n",
    "\n",
    "class LogData:\n",
    "    def __init__(self, width, height, time_stamp, frame):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.time_stamp = time_stamp\n",
    "        self.frame = frame\n",
    "\n",
    "    def toJson(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.toJson()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = 'pig_yolo_test.mov'\n",
    "save_image_path = \"crop-pig\"\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, size)\n",
    "\n",
    "frame_number = 0\n",
    "\n",
    "with open('obj.names', 'rt') as f:\n",
    "    names = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "logData = LogData(int(width), int(height), str(datetime.now()), [])\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame_number += 1\n",
    "    counter = 0\n",
    "    pig_dict = {}\n",
    "\n",
    "    if ret:\n",
    "        classes, confidences, boxes = net.detect(frame, confThreshold=0.45, nmsThreshold=0.45)\n",
    "        pig_index = 0\n",
    "        display_index = 0\n",
    "\n",
    "        frame_log = Frame(frame_number,len(boxes), [])\n",
    "\n",
    "        for classId, confidence, box in zip(classes.flatten(), confidences.flatten(), boxes):\n",
    "            counter = counter + 1\n",
    "            left, top, width, height = box\n",
    "            image = frame[top:top + height, left:left + width]\n",
    "            classes_te, confidences_te, boxes_te = tail_ear.detect(image, confThreshold=0.4, nmsThreshold=0.4)\n",
    "\n",
    "            tail_na = 'not visible'\n",
    "            pigData = PigData([int(left), int(top)], [int(width), int(height)], tail_na, [], [], [], [], False)\n",
    "\n",
    "            for classId_tail_ear, box_tail_ear in zip(classes_te, boxes_te):\n",
    "                if classId_tail_ear == 0:  #curly\n",
    "                    pigData.tail_type = 'curly'\n",
    "                    left, top, width, height = box_tail_ear\n",
    "                    pigData.tail_pos = [int(pigData.pig_pos[0]+left), int(pigData.pig_pos[0]+top)]\n",
    "                    pigData.tail_size = [int(width), int(height)]\n",
    "                elif classId_tail_ear == 1:  #straight\n",
    "                    pigData.tail_type = 'straight'\n",
    "                    left, top, width, height = box_tail_ear\n",
    "                    pigData.tail_pos = [int(pigData.pig_pos[0]+left), int(pigData.pig_pos[0]+top)]\n",
    "                    pigData.tail_size = [int(width), int(height)]\n",
    "                elif classId_tail_ear == 2:  #ear\n",
    "                    pigData.ear_visible = True\n",
    "                    left, top, width, height = box_tail_ear\n",
    "                    pigData.ear_pos.append([int(pigData.pig_pos[0]+left), int(pigData.pig_pos[0]+top)])\n",
    "                    pigData.ear_size.append([int(width), int(height)])\n",
    "\n",
    "            for cl_te, con_te, box_te in zip(classes_te, confidences_te, boxes_te):\n",
    "                label = '%.2f' % confidence\n",
    "                box_color = None\n",
    "                if cl_te == 0:  #curly\n",
    "                    label = '(curly): %s' % label\n",
    "                    box_color = (255, 0, 0)\n",
    "                elif cl_te == 1:  #straight\n",
    "                    label = '(straight): %s' % label\n",
    "                    box_color = (255, 0, 0)\n",
    "                elif cl_te == 2:  #ear\n",
    "                    label = '(ear): %s' % label\n",
    "                    box_color = (0, 0, 255)\n",
    "                labelsize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "                l, t, width, height = box_te\n",
    "                left = pigData.pig_pos[0]+l\n",
    "                top = pigData.pig_pos[1]+t\n",
    "                top = max(top, labelsize[1])\n",
    "                cv2.rectangle(frame, [left, top, width, height], color=box_color, thickness=2)\n",
    "                cv2.rectangle(frame, (left, top - labelsize[1]), (left + labelsize[0], top + baseLine), (255, 255, 255), cv2.FILLED)\n",
    "                cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (219, 0, 0))\n",
    "\n",
    "            frame_log.pigs_data.append(pigData)\n",
    "            logData.frame.append(frame_log)\n",
    "\n",
    "            pig_dict[pig_index] = pigData\n",
    "            pig_index = pig_index + 1\n",
    "\n",
    "        for classId, confidence, box in zip(classes.flatten(), confidences.flatten(), boxes):\n",
    "            label = '%.2f' % confidence\n",
    "            if display_index in pig_dict.keys():\n",
    "                label = '%s(%s tail): %s' % (names[classId], pig_dict[display_index].tail_type, label)\n",
    "            else:\n",
    "                label = '%s(tail not visible): %s' % (names[classId], label)\n",
    "            labelsize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            left, top, width, height = box\n",
    "            top = max(top, labelsize[1])\n",
    "            cv2.rectangle(frame, box, color=(2, 255, 0), thickness=2)\n",
    "            cv2.rectangle(frame, (left, top - labelsize[1]), (left + labelsize[0], top + baseLine), (255, 255, 255),\n",
    "                          cv2.FILLED)\n",
    "            cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "            display_index = display_index + 1\n",
    "\n",
    "        jsonLog = json.loads(logData.toJson())\n",
    "\n",
    "        with open(f\"{video}.json\", \"w\") as outfile:\n",
    "            json.dump(jsonLog, outfile)\n",
    "\n",
    "        out.write(frame)\n",
    "        # cv2.namedWindow('Objet Detection YOLO',cv2.WINDOW_NORMAL)\n",
    "        # cv2.resizeWindow('Objet Detection YOLO', 1600,900)\n",
    "        # cv2.imshow(\"Objet Detection YOLO\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 13:  #13 is the Enter Key\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get back the webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed4d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}